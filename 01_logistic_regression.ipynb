{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_logistic_regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalbertii/Modele-klasyfikacyjne/blob/main/01_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWts5-Puv3BL"
      },
      "source": [
        "**Model klasyfikacji binarnej**\n",
        "```\n",
        "!pip install scikit-learn\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjtisHd5whjO"
      },
      "source": [
        "### <a name='a1'></a> Import bibliotek"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gONRoC3wE4hV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwB7JWYcv4P-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.figure_factory as ff\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "\n",
        "sns.set(font_scale=1.3)\n",
        "np.set_printoptions(precision=6, suppress=True, edgeitems=10, linewidth=100000,\n",
        "                    formatter=dict(float=lambda x: f'{x:.2f}'))\n",
        "np.random.seed(42)\n",
        "sklearn.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt_AYVtZ0Pgl"
      },
      "source": [
        "###  <a name='a2'></a>  Regresja Logistyczna (Logistic Regression) -\n",
        "\n",
        "Pomimo nazwy jest to liniowy model do zadań klasyfikacyjnych. Inna nazwa Logit Regression.\n",
        "\n",
        "#### Przykłady zastosowań:\n",
        "- przewidywanie czy mail jest spamem, czy też nie\n",
        "- przewidywanie czy użytkownik kliknie w reklamę\n",
        "- przewidywanie czy nowotwór jest złośliwy czy też nie\n",
        "- przewidywanie czy dłużnik spłaci wierzycielowi dług, czy też zajdzie zdarzenie default\n",
        "- przewidywanie czy transakcja jest próbą oszustwa\n",
        "\n",
        "Przy budowie modelu regresji logistycznej wykorzystamy funkcję sigmoid. Definiuje się ją wzorem:\n",
        "$$sigmoid(x) = \\frac{1}{1+e^{-x}}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8NAT_uFkChZ"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "X = np.arange(-5, 5, 0.1)\n",
        "y = sigmoid(X)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(X, y)\n",
        "plt.title('Funkcja Sigmoid')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAuOPAi6kCy3"
      },
      "source": [
        "Następnie rozważmy funkcję liniową $y = w_0 + w_1x$. Podstawiając to do funkcji sigmoid otrzymujemy:\n",
        "$$p(x) = \\frac{1}{1 + e^{-(w_0 + w_1x)}}$$\n",
        "Dzięki temu przekształceniu regresja logistyczna zwraca nam wartości z przedziału $(0, 1)$ co możemy interpretować jako prawdopodobieństwo i na podstawie tych prawdopodobieństw przewidywać poszczególne klasy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJS_z9QUwx0N"
      },
      "source": [
        "###  <a name='a3'></a> Załadowanie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkcj5Yb_VhrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f80051-3419-4d6a-dc5d-e8951c2be70f"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "raw_data = load_breast_cancer()\n",
        "raw_data.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ_G5IVqeJj_"
      },
      "source": [
        "print(raw_data.DESCR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_data.feature_names)"
      ],
      "metadata": {
        "id": "WGd-AgTVM3GV",
        "outputId": "2f83833e-b97a-401f-cb9e-d12c4ed4f402",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area' 'mean smoothness' 'mean compactness' 'mean concavity' 'mean concave points' 'mean symmetry' 'mean fractal dimension' 'radius error' 'texture error' 'perimeter error' 'area error' 'smoothness error' 'compactness error' 'concavity error' 'concave points error' 'symmetry error' 'fractal dimension error' 'worst radius' 'worst texture' 'worst perimeter' 'worst area' 'worst smoothness' 'worst compactness' 'worst concavity' 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zfpVetA1Vzj"
      },
      "source": [
        "all_data = raw_data.copy()\n",
        "\n",
        "data = all_data['data']\n",
        "target = all_data['target']\n",
        "\n",
        "print(f'rozmiar data: {data.shape}')\n",
        "print(f'rozmiar target: {target.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tworzę dataframe na potrzeby wizualizacji i wtępnej analizy danych\n",
        "df_a = pd.DataFrame(data,columns=raw_data.feature_names)\n",
        "#df_a.columns = 'Imię', 'Wiek'\n",
        "df_a.head()"
      ],
      "metadata": {
        "id": "jo0k6MmoKN7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do wczesniej zdefiniowanego  dataframe dodaje kolumne ze zmienna objasnianą\n",
        "df_a['outcome'] = pd.DataFrame(target)"
      ],
      "metadata": {
        "id": "MwDAnZ42KbOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_a.head()"
      ],
      "metadata": {
        "id": "VTK0Hf2ZKtUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# analiza statystyczna zbioru danych\n",
        "df_a.describe().T"
      ],
      "metadata": {
        "id": "HXCez5dkFL0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sprawdzamy korelacje zmiennych\n",
        "df_a.corr()['outcome'].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "dz58yPMlLTbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sprawdzenie rozkładu unikalnych wartości zmiennej objaśnianej\n",
        "print(np.unique(df_a['outcome'], return_counts=True))"
      ],
      "metadata": {
        "id": "ydlXcSebaKaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QALWVO-j2BoE"
      },
      "source": [
        "###  <a name='a4'></a> Podział danych na zbiór treningowy i testowy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji8uRYBG1334"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target)\n",
        "\n",
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'y_train shape: {y_train.shape}')\n",
        "print(f'X_test shape: {X_test.shape}')\n",
        "print(f'y_test shape: {y_test.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr-uabGbhX1w"
      },
      "source": [
        "###  <a name='a44'></a> Przygotowanie danych do modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nMviOG7fcDS"
      },
      "source": [
        "X_train[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LudLC-D4gOCi"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# ważne !!!!\n",
        "# tylko na danych treningowych\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# skalujemy zarówno dane treningowe jak i testowe\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_train[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns_ctZx-hoZc"
      },
      "source": [
        "scaler.mean_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4VX1NWZhqnN"
      },
      "source": [
        "# odchylenie standardowe\n",
        "scaler.scale_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhrp8Nqr2azD"
      },
      "source": [
        "###<a name='a5'></a>  Dopasowanie modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqOw73xE2LoZ"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgZm_dZFxZqc"
      },
      "source": [
        "###<a name='a6'></a>  Predykcja na podstawie modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFBaG4tp2u99"
      },
      "source": [
        "y_pred = log_reg.predict(X_test)\n",
        "y_pred[:30]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xWVJXlre5a1"
      },
      "source": [
        "# wartości prawdopodobieństw dla klasy 0 i dla klasy 1\n",
        "y_prob = log_reg.predict_proba(X_test)\n",
        "y_prob[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IusW8zgExjea"
      },
      "source": [
        "###<a name='a7'></a>  Ocena modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cL8cMp72zl2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "#plot_confusion_matrix(cm)\n",
        "print(cm)\n",
        "\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SkN3JJtyDPR"
      },
      "source": [
        "def plot_confusion_matrix(cm):\n",
        "    # klasyfikacja binarna\n",
        "    cm = cm[::-1]\n",
        "    cm = pd.DataFrame(cm, columns=['pred_0', 'pred_1'], index=['true_1', 'true_0'])\n",
        "\n",
        "    fig = ff.create_annotated_heatmap(z=cm.values, x=list(cm.columns), y=list(cm.index),\n",
        "                                      colorscale='ice', showscale=True, reversescale=True)\n",
        "    fig.update_layout(width=500, height=500, title='Confusion Matrix', font_size=16)\n",
        "    fig.show()\n",
        "\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkKRIFi8xxvh"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Precision** - ile obserwacji przewidywanych jako pozytywne są w rzeczywistości pozytywne\n",
        "\n",
        "**Recall** - jak wiele obserwacji z wszystkich poytywnych sklasyfikowaliśmy jako pozytywne"
      ],
      "metadata": {
        "id": "KOGCeZv9IgtL"
      }
    }
  ]
}