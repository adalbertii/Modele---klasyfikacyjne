{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0aZh3YVMqVE/XCSsuhOZN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalbertii/Modele-klasyfikacyjne/blob/main/CNN_plant_case.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM1iuglb3wqw"
      },
      "outputs": [],
      "source": [
        "# Importing Keras\n",
        "from keras.models import Sequential                          # Neural network model as a sequence of layers.\n",
        "from keras.layers import Conv2D                              # Convolutional layer\n",
        "from keras.layers import MaxPooling2D                        # Max pooling layer\n",
        "from keras.layers import Flatten                             # Layer used to flatten 2D arrays for fully-connected layers.\n",
        "from keras.layers import Dense                               # This layer adds fully-connected layers to the neural network.\n",
        "from keras.layers import Dropout                             # This serves to prevent overfitting by dropping out a random set of activations.\n",
        "from keras.layers import BatchNormalization                  # This is used to normalize the activations of the neurons.\n",
        "from keras.layers import Activation                          # Layer for activation functions\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint   # Classes used to save weights and stop training when improvements reach a limit\n",
        "from keras.models import load_model                          # This helps us to load trained models\n",
        "# Preprocessing layers\n",
        "from keras.layers import Rescaling                           # This layer rescales pixel values\n",
        "\n",
        "# Importing TensorFlow\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring notebook\n",
        "seed = 123\n",
        "paper_color = '#EEF6FF'\n",
        "bg_color = '#EEF6FF'\n",
        "#colormap =\n",
        "#template ="
      ],
      "metadata": {
        "id": "s1XWa9A63_yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_resizer(paths):\n",
        "    \"\"\"\n",
        "    This function resizes the input images\n",
        "    \"\"\"\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        resized_images = list(executor.map(lambda x: Image.open(x).resize((350,250)), paths))\n",
        "    return resized_images\n",
        "\n",
        "def plot_images_list(images, title, subtitle):\n",
        "    '''\n",
        "    This functions helps to plot a matrix of images in a list\n",
        "    '''\n",
        "    fig = sp.make_subplots(rows=3, cols=3)\n",
        "    images = image_resizer(images)\n",
        "\n",
        "    traces = []\n",
        "    for i in range(min(9, len(images))):\n",
        "        img = go.Image(z=images[i])\n",
        "        traces.append((img, i//3+1, i%3+1))\n",
        "\n",
        "    fig.add_traces([trace[0] for trace in traces],\n",
        "                  rows = [trace[1] for trace in traces],\n",
        "                  cols = [trace[2] for trace in traces])\n",
        "\n",
        "    fig.update_layout(\n",
        "        title={'text': f'<b>{title}<br>  <i><sub>{subtitle}</sub></i></b>',\n",
        "               'font': dict(size = 22)},\n",
        "        height=800,\n",
        "        width=800,\n",
        "        margin=dict(t=110, l=80),\n",
        "        plot_bgcolor=bg_color,paper_bgcolor=paper_color\n",
        "        #template=template\n",
        "    )\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "iHvPNEKj4IL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "        strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
        "        print('\\nGPU Found! Using GPU...')\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    print('Number of replicas:', strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "id": "KpoXzeI74L33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading training, testing, and validation directories\n",
        "train_dir = '/kaggle/input/plant-disease-recognition-dataset/Train/Train'\n",
        "test_dir = '/kaggle/input/plant-disease-recognition-dataset/Test/Test'\n",
        "val_dir = '/kaggle/input/plant-disease-recognition-dataset/Validation/Validation'"
      ],
      "metadata": {
        "id": "XYyPuB2I4NWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Giving names to each directory\n",
        "directories = {\n",
        "    train_dir: 'Train',\n",
        "    test_dir: 'Test',\n",
        "    val_dir: 'Validation'\n",
        "    }\n",
        "\n",
        "# Naming subfolders\n",
        "subfolders = ['Healthy', 'Powdery', 'Rust']\n",
        "\n",
        "print('\\n* * * * * Number of files in each folder * * * * *\\n')\n",
        "\n",
        "# Counting the total of pictures inside each subfolder and directory\n",
        "for dir, name in directories.items():\n",
        "    total = 0\n",
        "    for sub in subfolders:\n",
        "        path = os.path.join(dir, sub)\n",
        "        num_files = len([f for f in os.listdir(path) if os.path.join(path, f)])\n",
        "        total += num_files\n",
        "        print(f'\\n{name}/{sub}: {num_files}')\n",
        "    print(f'\\n  Total: {total}')\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "uNXDxCJc4Rwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_dimensions = set()\n",
        "\n",
        "for dir, name in directories.items():\n",
        "    for sub in subfolders:\n",
        "        folder_path = os.path.join(dir, sub)\n",
        "\n",
        "        for file in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, file)\n",
        "            with Image.open(image_path) as img:\n",
        "                unique_dimensions.add(img.size)\n",
        "\n",
        "if len(unique_dimensions) == 1:\n",
        "    print(f\"\\nAll images have the same dimensions: {unique_dimensions.pop()}\")\n",
        "else:\n",
        "    print(f\"\\nFound {len(unique_dimensions)} unique image dimensions: {unique_dimensions}\")"
      ],
      "metadata": {
        "id": "ux-gIN4j4Vk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if all the images in the dataset have the same dimensions\n",
        "dims_counts = defaultdict(int)\n",
        "\n",
        "for dir, name in directories.items():\n",
        "    for sub in subfolders:\n",
        "        folder_path = os.path.join(dir, sub)\n",
        "\n",
        "        for file in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, file)\n",
        "            with Image.open(image_path) as img:\n",
        "                dims_counts[img.size] += 1\n",
        "\n",
        "for dimension, count in dims_counts.items():\n",
        "    print(f\"\\nDimension {dimension}: {count} images\")"
      ],
      "metadata": {
        "id": "97EK1GYV4aTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking images dtype\n",
        "all_uint8 = True\n",
        "all_in_range = True\n",
        "\n",
        "for dir, name in directories.items():\n",
        "    for sub in subfolders:\n",
        "        folder_path = os.path.join(dir, sub)\n",
        "\n",
        "        for file in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, file)\n",
        "            with Image.open(image_path) as img:\n",
        "                img_array = np.array(img)\n",
        "\n",
        "            if img_array.dtype == 'uint8':\n",
        "                all_uint8 = False\n",
        "\n",
        "            if img_array.min() < 0 or img_array.max() > 255:\n",
        "                all_in_range = False\n",
        "\n",
        "if all_uint8:\n",
        "    print(\" - All images are of data type uint8\\n\")\n",
        "else:\n",
        "    print(\" - Not all images are of data type uint8\\n\")\n",
        "\n",
        "if all_in_range:\n",
        "    print(\" - All images have pixel values ranging from 0 to 255\")\n",
        "else:\n",
        "    print(\" - Not all images have the same pixel values from 0 to 255\")"
      ],
      "metadata": {
        "id": "pm8h-nCL4d1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the directory for each class in the training dataset\n",
        "train_healthy_dir = train_dir + \"/\" + 'Healthy'\n",
        "train_rust_dir = train_dir + \"/\" + 'Rust'\n",
        "train_powdery_dir = train_dir + \"/\" + 'Powdery'\n",
        "\n",
        "# Selecting 9 random pictures from each directory\n",
        "healthy_files = random.sample(os.listdir(train_healthy_dir), 9)\n",
        "rust_files = random.sample(os.listdir(train_rust_dir), 9)\n",
        "powdery_files = random.sample(os.listdir(train_powdery_dir), 9)"
      ],
      "metadata": {
        "id": "9nYg_U6Z4inK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting healthy plants\n",
        "healthy_images = [os.path.join(train_healthy_dir, f) for f in healthy_files]\n",
        "plot_images_list(healthy_images, \"Healthy Plants\", \"Training Dataset\")"
      ],
      "metadata": {
        "id": "tbrPexbU4msz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting rust plants\n",
        "rust_images = [os.path.join(train_rust_dir, f) for f in rust_files]\n",
        "plot_images_list(rust_images, \"Rust Plants\", \"Training Dataset\")"
      ],
      "metadata": {
        "id": "lLkcLRvG4pkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting powdery plants\n",
        "powdery_images = [os.path.join(train_powdery_dir, f) for f in powdery_files]\n",
        "plot_images_list(powdery_images, \"Powdery Plants\", \"Training Dataset\")"
      ],
      "metadata": {
        "id": "pToUzkrY4stl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Dataset for the Training data\n",
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,  # Directory where the Training images are located\n",
        "    labels = 'inferred', # Classes will be inferred according to the structure of the directory\n",
        "    label_mode = 'categorical',\n",
        "    class_names = ['Healthy', 'Powdery', 'Rust'],\n",
        "    batch_size = 16,    # Number of processed samples before updating the model's weights\n",
        "    image_size = (256, 256), # Defining a fixed dimension for all images\n",
        "    shuffle = True,  # Shuffling data\n",
        "    seed = seed,  # Random seed for shuffling and transformations\n",
        "    validation_split = 0, # We don't need to create a validation set from the training set\n",
        "    crop_to_aspect_ratio = True # Resize images without aspect ratio distortion\n",
        ")"
      ],
      "metadata": {
        "id": "UIRNHhqN4vvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataset for the Test data\n",
        "test = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    class_names = ['Healthy', 'Powdery', 'Rust'],\n",
        "    batch_size = 16,\n",
        "    image_size = (256, 256),\n",
        "    shuffle = True,\n",
        "    seed = seed,\n",
        "    validation_split = 0,\n",
        "    crop_to_aspect_ratio = True\n",
        ")"
      ],
      "metadata": {
        "id": "7AF5P-jO46Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataset for the Test data\n",
        "validation = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    class_names = ['Healthy', 'Powdery', 'Rust'],\n",
        "    batch_size = 16,\n",
        "    image_size = (256, 256),\n",
        "    shuffle = True,\n",
        "    seed = seed,\n",
        "    validation_split = 0,\n",
        "    crop_to_aspect_ratio = True\n",
        ")"
      ],
      "metadata": {
        "id": "V55XA9CR483T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nTraining Dataset:', train)\n",
        "print('\\nTesting Dataset:', test)\n",
        "print('\\nValidation Dataset:', validation)"
      ],
      "metadata": {
        "id": "ZKoMAsb-4_wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking minimum and maximum pixel values in the Validation dataset\n",
        "min_value = float('inf')\n",
        "max_value = -float('inf')\n",
        "\n",
        "for img, label in validation:\n",
        "    batch_min = tf.reduce_min(img)\n",
        "    batch_max = tf.reduce_max(img)\n",
        "\n",
        "    min_value = min(min_value, batch_min.numpy())\n",
        "    max_value = max(max_value, batch_max.numpy())\n",
        "\n",
        "print('\\nMinimum pixel value in the Validation dataset', min_value)\n",
        "print('\\nMaximum pixel value in the Validation dataset', max_value)"
      ],
      "metadata": {
        "id": "L-4fT0SD5DPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = Rescaling(1./255) # Defining scaler values between 0 to 1"
      ],
      "metadata": {
        "id": "TIEl-eMz5H86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescaling datasets\n",
        "train = train.map(lambda x, y: (scaler(x), y))\n",
        "test = test.map(lambda x, y: (scaler(x), y))\n",
        "validation = validation.map(lambda x, y: (scaler(x), y))"
      ],
      "metadata": {
        "id": "F-1Lnyok5LKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking minimum and maximum pixel values in the Validation dataset\n",
        "min_value = float('inf')\n",
        "max_value = -float('inf')\n",
        "\n",
        "for img, label in validation:\n",
        "    batch_min = tf.reduce_min(img)\n",
        "    batch_max = tf.reduce_max(img)\n",
        "\n",
        "    min_value = min(min_value, batch_min.numpy())\n",
        "    max_value = max(max_value, batch_max.numpy())\n",
        "\n",
        "print('\\nMinimum pixel value in the Validation dataset', min_value)\n",
        "print('\\nMaximum pixel value in the Validation dataset', max_value)"
      ],
      "metadata": {
        "id": "6LAGvLkj5N1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating data augmentation pipeline\n",
        "augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.RandomRotation(\n",
        "        factor = (-.25, .3),\n",
        "        fill_mode = 'reflect',\n",
        "        interpolation = 'bilinear',\n",
        "        seed = seed),\n",
        "\n",
        "\n",
        "        tf.keras.layers.RandomBrightness(\n",
        "        factor = (-.45, .45),\n",
        "        value_range = (0.0, 1.0),\n",
        "        seed = seed),\n",
        "\n",
        "        tf.keras.layers.RandomContrast(\n",
        "        factor = (.5),\n",
        "        seed = seed)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "FQoOTVJW5RcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation.build((None, 256, 256, 3)) # Building model\n",
        "# Plotting model\n",
        "tf.keras.utils.plot_model(augmentation,\n",
        "                          show_shapes = True,\n",
        "                          show_layer_names = True,\n",
        "                          expand_nested = True)"
      ],
      "metadata": {
        "id": "mYhz2XJ55XcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiating model on GPU\n",
        "with strategy.scope():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(augmentation) # Adding data augmentation pipeline to the model\n",
        "\n",
        "    # Feature Learning Layers\n",
        "    model.add(Conv2D(32,                  # Number of filters/Kernels\n",
        "                     (3,3),               # Size of kernels (3x3 matrix)\n",
        "                     strides = 1,         # Step size for sliding the kernel across the input (1 pixel at a time).\n",
        "                     padding = 'same',    # 'Same' ensures that the output feature map has the same dimensions as the input by padding zeros around the input.\n",
        "                    input_shape = (256,256,3) # Input image shape\n",
        "                    ))\n",
        "    model.add(Activation('relu'))# Activation function\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(64, (5,5), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (3,3), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(256, (5,5), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(512, (3,3), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Flattening tensors\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully-Connected Layers\n",
        "    model.add(Dense(2048))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(3, activation = 'softmax')) # Classification layer"
      ],
      "metadata": {
        "id": "fDsPpNFx5ayS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(0.0001), # 1e-4\n",
        "              loss = 'categorical_crossentropy', # Ideal for multiclass tasks\n",
        "              metrics = ['accuracy']) # Evaluation metric"
      ],
      "metadata": {
        "id": "YkmYMRLw5lOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining an Early Stopping and Model Checkpoints\n",
        "early_stopping = EarlyStopping(monitor = 'val_accuracy',\n",
        "                              patience = 5, mode = 'max',\n",
        "                              restore_best_weights = True)\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model.h5',\n",
        "                            monitor = 'val_accuracy',\n",
        "                            save_best_only = True)"
      ],
      "metadata": {
        "id": "JuZ-TTCs5oml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Testing Model\n",
        "try:\n",
        "    history = model.fit(\n",
        "        train, epochs = 50,\n",
        "        validation_data = test,\n",
        "        callbacks = [early_stopping, checkpoint])\n",
        "except Exception as e:\n",
        "    print(\"An error occurred:\", e)"
      ],
      "metadata": {
        "id": "BnyOzx8z5t4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating subplot\n",
        "fig = make_subplots(rows=1,\n",
        "                    cols=2,\n",
        "                    subplot_titles=['<b>Loss Over Epochs</b>', '<b>Accuracy Over Epochs</b>'],\n",
        "                    horizontal_spacing=0.2)\n",
        "\n",
        "# Loss over epochs\n",
        "train_loss = go.Scatter(x=list(range(len(history.history['loss']))),\n",
        "                        y=history.history['loss'],\n",
        "                        mode='lines',\n",
        "                        line=dict(color='rgba(0, 67, 162, .75)', width=4.75),\n",
        "                        name='Training',\n",
        "                        showlegend = False)\n",
        "\n",
        "val_loss = go.Scatter(x=list(range(len(history.history['val_loss']))),\n",
        "                      y=history.history['val_loss'],\n",
        "                      mode='lines',\n",
        "                      line=dict(color='rgba(255, 132, 0, .75)', width=4.75),\n",
        "                      name='Test',\n",
        "                      showlegend = False)\n",
        "\n",
        "\n",
        "fig.add_trace(train_loss, row=1, col=1)\n",
        "fig.add_trace(val_loss, row=1, col=1)\n",
        "\n",
        "# Accuray over epochs\n",
        "train_acc = go.Scatter(x=list(range(len(history.history['accuracy']))),\n",
        "                       y=history.history['accuracy'],\n",
        "                       mode='lines',\n",
        "                       line=dict(color='rgba(0, 67, 162, .75)', width=4.75),\n",
        "                       name='Training',\n",
        "                       showlegend = True)\n",
        "\n",
        "val_acc = go.Scatter(x=list(range(len(history.history['val_accuracy']))),\n",
        "                     y=history.history['val_accuracy'],\n",
        "                     mode='lines',\n",
        "                     line=dict(color='rgba(255, 132, 0, .75)', width=4.75),\n",
        "                     name='Test',\n",
        "                     showlegend = True)\n",
        "\n",
        "\n",
        "fig.add_trace(train_acc, row=1, col=2)\n",
        "fig.add_trace(val_acc, row=1, col=2)\n",
        "\n",
        "# Updating layout\n",
        "fig.update_layout(\n",
        "    title={'text': '<b>Loss and Accuracy Over Epochs</b>', 'x': 0.025, 'xanchor': 'left'},\n",
        "    margin=dict(t=100),\n",
        "    plot_bgcolor=bg_color,paper_bgcolor=paper_color,\n",
        "    height=500, width=1000,\n",
        "    showlegend= True\n",
        ")\n",
        "\n",
        "fig.update_yaxes(title_text = 'Loss', row = 1, col = 1)\n",
        "fig.update_yaxes(title_text = 'Accuracy', row = 1, col = 2)\n",
        "\n",
        "fig.update_xaxes(title_text = 'Epoch', row = 1, col = 1)\n",
        "fig.update_xaxes(title_text = 'Epoch', row = 1, col = 2)\n",
        "\n",
        "# Showing figure\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "HCzGifKw5u-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model) # Plotting model"
      ],
      "metadata": {
        "id": "Ml05wS8v51R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary() # Printing model summary"
      ],
      "metadata": {
        "id": "MAz_x4W855wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading best weights\n",
        "model.load_weights('best_model.h5')"
      ],
      "metadata": {
        "id": "i6toPRaS6BrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(validation)  # Running model on the validation dataset\n",
        "val_loss, val_acc = model.evaluate(validation) # Obtaining Loss and Accuracy on the val dataset\n",
        "\n",
        "print('\\nValidation Loss: ', val_loss)\n",
        "print('\\nValidation Accuracy: ', np.round(val_acc * 100), '%')"
      ],
      "metadata": {
        "id": "dmL-2m3a6EJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading an image from the Validation/ Powdery directory\n",
        "image_path = '/kaggle/input/plant-disease-recognition-dataset/Validation/Validation/Powdery/9b6a318cc5721d73.jpg'\n",
        "original_image = Image.open(image_path)\n",
        "og_width, og_height = original_image.size\n",
        "\n",
        "# Resizing image for optimal performance\n",
        "new_width = int(og_width * .20) # 20% of the original size\n",
        "new_height = int(og_height * .20) # 20% of the original size\n",
        "\n",
        "resized_img = original_image.resize((new_width, new_height))\n",
        "print('Picture of a Powdery Plant: \\n')\n",
        "resized_img"
      ],
      "metadata": {
        "id": "R_uPikAZ6IFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually preprocessing image\n",
        "preprocessed_image = original_image.resize((256, 256))\n",
        "preprocessed_image = np.array(preprocessed_image) / 255.0\n",
        "\n",
        "preds = model.predict(np.expand_dims(preprocessed_image, axis = 0))\n",
        "labels = ['Healthy', 'Powdery', 'Rust']\n",
        "\n",
        "preds_class = np.argmax(preds)\n",
        "preds_label = labels[preds_class]\n",
        "\n",
        "print(f'\\nPredicted Class: {preds_label}')\n",
        "print(f'\\nConfidence Score: {preds[0][preds_class]}')"
      ],
      "metadata": {
        "id": "x73skX2O6Jrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading an image from the Validation/ Rust directory\n",
        "image_path = '/kaggle/input/plant-disease-recognition-dataset/Validation/Validation/Rust/8152cfbd5a28b5d2.jpg'\n",
        "original_image = Image.open(image_path)\n",
        "og_width, og_height = original_image.size\n",
        "\n",
        "# Resizing image for optimal performance\n",
        "new_width = int(og_width * .20) # 20% of the original size\n",
        "new_height = int(og_height * .20) # 20% of the original size\n",
        "\n",
        "resized_img = original_image.resize((new_width, new_height))\n",
        "print('Picture of a Rust Plant: \\n')\n",
        "resized_img"
      ],
      "metadata": {
        "id": "INtV4-1u6OxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually preprocessing image\n",
        "preprocessed_image = original_image.resize((256, 256))\n",
        "preprocessed_image = np.array(preprocessed_image) / 255.0\n",
        "\n",
        "preds = model.predict(np.expand_dims(preprocessed_image, axis = 0))\n",
        "labels = ['Healthy', 'Powdery', 'Rust']\n",
        "\n",
        "preds_class = np.argmax(preds)\n",
        "preds_label = labels[preds_class]\n",
        "\n",
        "print(f'\\nPredicted Class: {preds_label}')\n",
        "print(f'\\nConfidence Score: {preds[0][preds_class]}')"
      ],
      "metadata": {
        "id": "In3WCQAG6Sxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading an image from the Validation/ Healthy directory\n",
        "image_path = '/kaggle/input/plant-disease-recognition-dataset/Validation/Validation/Healthy/9c99786a63786571.jpg'\n",
        "original_image = Image.open(image_path)\n",
        "og_width, og_height = original_image.size\n",
        "\n",
        "# Resizing image for optimal performance\n",
        "new_width = int(og_width * .20) # 20% of the original size\n",
        "new_height = int(og_height * .20) # 20% of the original size\n",
        "\n",
        "resized_img = original_image.resize((new_width, new_height))\n",
        "print('Picture of a Healthy Plant: \\n')\n",
        "resized_img"
      ],
      "metadata": {
        "id": "cb2BwSvi6Xht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually preprocessing image\n",
        "preprocessed_image = original_image.resize((256, 256))\n",
        "preprocessed_image = np.array(preprocessed_image) / 255.0\n",
        "\n",
        "preds = model.predict(np.expand_dims(preprocessed_image, axis = 0))\n",
        "labels = ['Healthy', 'Powdery', 'Rust']\n",
        "\n",
        "preds_class = np.argmax(preds)\n",
        "preds_label = labels[preds_class]\n",
        "\n",
        "print(f'\\nPredicted Class: {preds_label}')\n",
        "print(f'\\nConfidence Score: {preds[0][preds_class]}')"
      ],
      "metadata": {
        "id": "nhJ3YRZ56cGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('plant_disease_classifier.h5') # Saving model"
      ],
      "metadata": {
        "id": "dgSzUUKj6g4c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}